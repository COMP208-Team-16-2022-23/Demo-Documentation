import{_ as s,a as r,b as l,c as d}from"./reset-11f8ff96.js";import{_ as c,a as h}from"./my_data_action-02e1ba07.js";import{_ as p,a as u,b as m,c as g,d as f,e as b,f as _,g as v}from"./forum-other-language-fb7cb47d.js";import{_ as y}from"./creating_nodes-f417a4eb.js";import{_ as w,M as k,p as x,q as T,R as e,t as a,N as n,a1 as i}from"./framework-efe98465.js";const A="/assets/data-processing-index-3e12858b.jpg",C="/assets/data-processing-new-processing-c94522df.jpg",D="/assets/data-processing-index-edit-05a9e91f.jpg",S="/assets/data-processing-index-delete-7db54f96.jpg",I="/assets/data-processing-project-page-867a7fe2.jpeg",N="/assets/data-processing-algorithm-list-63ee984a.jpg",L="/assets/data-processing-parameter-panel-bc926a57.jpg",P="/assets/data-processing-data-preview-3b8c4644.jpg",E="/assets/data-processing-my-data-result-3df82659.jpg",q="/assets/data_analysis-4e6b5c71.png",M="/assets/start_analysing-9a9d9a41.png",O="/assets/project_view-05b671cc.png",R="/assets/knn-a5a80e6f.png",j="/assets/result_view-949b8918.png",o="/assets/decision_matrix-cd327403.png",F="/assets/realiability_test-305f339a.png",z="/assets/ADF_test-0e1b812f.png",W="/assets/Bland_Altman-4b23c8ca.png",Y="/assets/k_nn-b5ea73e5.png",B="/assets/svm-2aed5cf0.png",U="/assets/decision_tree-91265ad0.png",G="/assets/forum-random-text-820d6aca.jpeg",H="/assets/forum-swear-word-editor-9aa88011.jpeg",K="/assets/forum-swear-word-post-dfbedc51.jpeg",V="/assets/creation_result-ceda0896.png",$="/assets/process_preparation-677590fa.png",J="/assets/process_1step-83bd3953.png",Z="/assets/process_2step-9ce0d879.png",Q={},X=e("h1",null,"Low-Code Data Analysis User Manual",-1),ee=e("p",null,[e("strong",null,"Author: 2022/23-COMP208-Team16")],-1),ae=e("p",null,"Haoran Lu, Jiaqi Liao, Jiawei Li, Zhan Jin, Ziqiu Jiang",-1),te=e("p",null,[e("strong",null,"Project Website")],-1),ne={href:"http://lcda.space",target:"_blank",rel:"noopener noreferrer"},ie=e("p",null,[e("strong",null,"Online Documentation")],-1),oe={href:"http://guide.lcda.space",target:"_blank",rel:"noopener noreferrer"},se=e("blockquote",null,[e("p",null,"As our website is a serverless architecture, this may cause the site to take longer to load. We apologise for any inconvenience this may cause you and ask for your patience and understanding.")],-1),re=e("p",null,[e("strong",null,"Table of Contents")],-1),le=e("p",null,"[TOC]",-1),de=e("h1",{id:"introduction",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#introduction","aria-hidden":"true"},"#"),a(" Introduction")],-1),ce=e("p",null,"Low-Code Data Analysis (LCDA) is a tool designed to simplify data analysis by minimizing programming requirements. With LCDA, users can analyze large data sets quickly and easily, without the need for writing complex code. The platform features a user-friendly interface that enables users to drag and drop data into the analysis and visualization results, making it an ideal tool for beginners in artificial intelligence, data scientists, business analysts, and anyone seeking to derive insights from data.",-1),he={href:"http://modules.xjtlu.edu.cn/?mod_code=INT104",target:"_blank",rel:"noopener noreferrer"},pe=e("h2",{id:"how-it-works",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#how-it-works","aria-hidden":"true"},"#"),a(" How It Works")],-1),ue={href:"https://flask.palletsprojects.com/en/latest/",target:"_blank",rel:"noopener noreferrer"},me=i('<p>To ensure that users can access the LCDA platform with ease, the team has implemented various security measures. The platform uses SSL encryption to secure user data during transmission and uses a secure login process to prevent unauthorized access. Additionally, the platform is regularly updated with the latest security patches to ensure that users are protected against any potential vulnerabilities.</p><h2 id="why-not" tabindex="-1"><a class="header-anchor" href="#why-not" aria-hidden="true">#</a> Why Not ...?</h2><h3 id="spss-statistics" tabindex="-1"><a class="header-anchor" href="#spss-statistics" aria-hidden="true">#</a> SPSS Statistics</h3><p>SPSS is a widely used data analysis software with an excellent set of products. While SPSS can perform far more specialized functions than LCDA, it requires a fee for usage, and its interface can be complex, making it challenging for beginners to use. In contrast, LCDA prioritizes user-friendly design and intuitive functionality, making it easy for beginners to get started with data analysis.</p><h3 id="python" tabindex="-1"><a class="header-anchor" href="#python" aria-hidden="true">#</a> Python</h3><p>Python is a popular programming language for artificial intelligence and data science, and its open-source nature makes it easily accessible. However, for beginners who are unfamiliar with programming, installing and using a large number of Python AI-related packages can be overwhelming, let alone mastering the use of functions in the library. LCDA is a Python-based web application that simplifies data analysis by packaging common data analysis algorithms, providing visualization tools, and offering user-friendly result pages. This reduces the cost of trial and error for beginners and enables them to learn new concepts through exploration.</p><p>Compared to SPSS and Python, LCDA offers an easy-to-use platform that combines the benefits of both. It provides a low-code solution that simplifies data analysis without sacrificing functionality, making it an ideal choice for beginners, data scientists, business analysts, and anyone looking to derive insights from data with ease.</p><h1 id="installation-and-deployment-guide" tabindex="-1"><a class="header-anchor" href="#installation-and-deployment-guide" aria-hidden="true">#</a> Installation and Deployment Guide</h1><h2 id="before-starting-the-installation" tabindex="-1"><a class="header-anchor" href="#before-starting-the-installation" aria-hidden="true">#</a> Before Starting the Installation</h2>',9),ge={href:"https://www.lcda.space/",target:"_blank",rel:"noopener noreferrer"},fe={href:"https://cloud.google.com/run",target:"_blank",rel:"noopener noreferrer"},be={href:"https://cloud.google.com/storage",target:"_blank",rel:"noopener noreferrer"},_e={href:"https://aws.amazon.com/rds/",target:"_blank",rel:"noopener noreferrer"},ve=e("p",null,"Please note that deploying LCDA in the cloud requires a certain level of technical expertise, and it is recommended that you have experience with cloud services before attempting to deploy LCDA on your own.",-1),ye=e("h2",{id:"prerequisites",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#prerequisites","aria-hidden":"true"},"#"),a(" Prerequisites")],-1),we={href:"https://docs.conda.io/en/latest/miniconda.html",target:"_blank",rel:"noopener noreferrer"},ke={href:"https://www.anaconda.com/products/distribution",target:"_blank",rel:"noopener noreferrer"},xe={href:"https://www.python.org/",target:"_blank",rel:"noopener noreferrer"},Te=e("code",null,"venv",-1),Ae={href:"https://git-scm.com/downloads",target:"_blank",rel:"noopener noreferrer"},Ce={href:"https://cloud.google.com/run",target:"_blank",rel:"noopener noreferrer"},De={href:"https://cloud.google.com/storage",target:"_blank",rel:"noopener noreferrer"},Se={href:"https://aws.amazon.com/rds/",target:"_blank",rel:"noopener noreferrer"},Ie=e("h2",{id:"installation-and-deployment-steps",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#installation-and-deployment-steps","aria-hidden":"true"},"#"),a(" Installation and Deployment Steps")],-1),Ne=e("p",null,"This section will help you step by step from scratch to deploying the LCDA platform.",-1),Le=i(`<li><p>Create and change into a new directory</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">mkdir</span> COMP208-202223-Team16
<span class="token builtin class-name">cd</span> COMP208-202223-Team16
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>Pull source code</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> clone https://github.com/COMP208-Team-16-2022-23/Group-Project-Code.git
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li><li><p>Change into project directory</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">cd</span> Group-Project-Code
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li><li><p>Create and activate a Python virtual environment</p><p>You can choose <code>venv</code> or <code>conda</code> virtual environments</p><blockquote><ul><li><p><code>venv</code> environment is suitable for <strong>short-term testing</strong> and can be deleted along with the project folder without affecting the system environment.</p></li><li><p><code>conda</code> environment is suitable for <strong>long-term development</strong> as it offers more comprehensive package management and environment management functions.</p></li></ul></blockquote><h4 id="venv-virtual-environment" tabindex="-1"><a class="header-anchor" href="#venv-virtual-environment" aria-hidden="true">#</a> <code>venv</code> virtual environment</h4><p>This command will create a virtual environment in the current directory.</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>python <span class="token parameter variable">-m</span> venv <span class="token builtin class-name">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Activate the virtual environment</p><ul><li>Bash:</li></ul><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">source</span> ./bin/activate
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li>CMD:</li></ul><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>.<span class="token punctuation">\\</span>Scripts<span class="token punctuation">\\</span>activate.bat
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Install the required packages</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>pip <span class="token function">install</span> <span class="token parameter variable">-r</span> requirements.txt
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h4 id="conda-virtual-environment" tabindex="-1"><a class="header-anchor" href="#conda-virtual-environment" aria-hidden="true">#</a> <code>Conda</code> virtual environment</h4><p>Create a Conda virtual environment named <code>COMP208</code> with Python version 3.10.</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>conda <span class="token function">env</span> create <span class="token parameter variable">-f</span> ./misc/environment.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Activate the virtual environment</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>conda activate COMP208
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li>`,4),Pe=e("p",null,"Configure cloud services",-1),Ee=e("p",null,"LCDA was originally designed to be deployed in the cloud. Therefore, configuring cloud services is an essential part of running LCDA smoothly. For each cloud service configuration tutorial, please refer to its official documentation, which will not be repeated in this article.",-1),qe={href:"https://aws.amazon.com/rds/",target:"_blank",rel:"noopener noreferrer"},Me={href:"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html",target:"_blank",rel:"noopener noreferrer"},Oe={href:"https://cloud.google.com/storage",target:"_blank",rel:"noopener noreferrer"},Re={href:"https://cloud.google.com/storage/docs",target:"_blank",rel:"noopener noreferrer"},je={href:"https://cloud.google.com/run",target:"_blank",rel:"noopener noreferrer"},Fe={href:"https://cloud.google.com/run/docs",target:"_blank",rel:"noopener noreferrer"},ze=e("p",null,"Do not worry, many cloud service providers offer users a certain amount of free trial quota. If LCDA is only used for testing, there will be no additional expenses.",-1),We=i(`<li><p>Configure <code>/secret.py</code></p><p>Before you can deploy and run LCDA, you need to configure the <code>/secret.py</code> file with relevant information. This file contains sensitive information such as API keys, database passwords, and other secrets that are required for the proper functioning of the application. In this case, it also includes relevant Google Cloud information.</p><p>The following is an example of configuring <code>/secret.py</code>:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> datetime <span class="token keyword">import</span> timedelta

<span class="token comment"># DOMAIN</span>
DOMAIN <span class="token operator">=</span> <span class="token string">&#39;Your google cloud run domain&#39;</span>

SECRET_KEY <span class="token operator">=</span> <span class="token string">&#39;Your secret key (i.e. a random string)&#39;</span>
PERMANENT_SESSION_LIFETIME <span class="token operator">=</span> timedelta<span class="token punctuation">(</span>minutes<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>

<span class="token comment"># Configuration for the database</span>
HOSTNAME <span class="token operator">=</span> <span class="token string">&#39;Your database hostname&#39;</span>
PORT <span class="token operator">=</span> <span class="token string">&#39;Your database port&#39;</span>
DATABASE <span class="token operator">=</span> <span class="token string">&#39;Your database name&#39;</span>
USERNAME <span class="token operator">=</span> <span class="token string">&#39;Your database account username&#39;</span>
PASSWORD <span class="token operator">=</span> <span class="token string">&#39;Your database account password&#39;</span>
LOCAL_TEST <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># set to True will ignore the above configuration and use local sqlite database called project.db</span>

<span class="token comment"># Configuration variables for email</span>
<span class="token comment"># configure the mail settings</span>
MAIL_SERVER <span class="token operator">=</span> <span class="token string">&#39;Your email server&#39;</span>
MAIL_PORT <span class="token operator">=</span> <span class="token number">465</span> <span class="token comment"># Your email server port</span>
MAIL_USE_SSL <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token comment"># Whether your email server uses SSL</span>
MAIL_USERNAME <span class="token operator">=</span> <span class="token string">&#39;Your email address&#39;</span>
MAIL_PASSWORD <span class="token operator">=</span> <span class="token string">&#39;Your email account password&#39;</span> 
MAIL_DEFAULT_SENDER <span class="token operator">=</span> <span class="token string">&#39;LCDA Team&#39;</span>
MAIL_MAX_EMAILS <span class="token operator">=</span> <span class="token boolean">None</span>

<span class="token comment"># Configuration variables for Google Cloud Storage</span>
GOOGLE_APPLICATION_CREDENTIALS <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment"># Your service account key, in json format.</span>
<span class="token punctuation">}</span>
BUCKET_NAME <span class="token operator">=</span> <span class="token string">&#39;Your Google Cloud Storage bucket name&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>Deploy LCDA locally</p><p>Bash:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">FLASK_APP</span><span class="token operator">=</span>app.py
<span class="token builtin class-name">export</span> <span class="token assign-left variable">FLASK_ENV</span><span class="token operator">=</span>development
flask run
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>CMD:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">set</span> <span class="token assign-left variable">FLASK_APP</span><span class="token operator">=</span>app.py
<span class="token builtin class-name">set</span> <span class="token assign-left variable">FLASK_ENV</span><span class="token operator">=</span>development
flask run
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>PowerShell:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token variable">$env</span>:FLASK_APP <span class="token operator">=</span> <span class="token string">&quot;app.py&quot;</span>
<span class="token variable">$env</span>:FLASK_ENV <span class="token operator">=</span> <span class="token string">&quot;development&quot;</span>
flask run
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li>`,2),Ye={href:"http://127.0.0.1:5000",target:"_blank",rel:"noopener noreferrer"},Be=i('<h1 id="authentication-of-users" tabindex="-1"><a class="header-anchor" href="#authentication-of-users" aria-hidden="true">#</a> Authentication of Users</h1><p>User authentication is an important part of our platform. To ensure that no user data is lost, most functions require a login. By registering, we ensure that your data is kept private and that you give your informed consent to our terms and policies.</p><blockquote><p>Note: You may not receive the expected email. If this is the case, please check that your email address is valid and check the spam folder of your mailbox. In some cases, you need to contact your email provider.</p></blockquote><h2 id="login" tabindex="-1"><a class="header-anchor" href="#login" aria-hidden="true">#</a> Login</h2><p>To access the platform, users must first authenticate themselves through the login process.</p><p><img src="'+l+'" alt="Login"></p><p>To login, follow these steps:</p>',7),Ue={href:"https://www.lcda.space/auth/login",target:"_blank",rel:"noopener noreferrer"},Ge=e("li",null,[e("p",null,"Enter your registered email address and password.")],-1),He=e("li",null,[e("p",null,`Click on the "Sign In" button. If the email address and password match what we have on record, you will be redirected to 'My Data' page or the page that requires login.`)],-1),Ke=e("h2",{id:"registration",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#registration","aria-hidden":"true"},"#"),a(" Registration")],-1),Ve=e("p",null,"To use our platform, you must first register an account.",-1),$e=e("p",null,[e("img",{src:s,alt:"Register"})],-1),Je=e("p",null,"To register, follow these steps:",-1),Ze={href:"https://www.lcda.space/auth/register",target:"_blank",rel:"noopener noreferrer"},Qe=e("li",null,"Enter a valid and unused username, your email address, and desired password. The password must be at least 8 characters long and contain at least one uppercase letter, one lowercase letter, and one digit.",-1),Xe={href:"https://www.lcda.space/legal/terms",target:"_blank",rel:"noopener noreferrer"},ea={href:"https://www.lcda.space/legal/privacy",target:"_blank",rel:"noopener noreferrer"},aa=e("li",null,'Check the "Agree to Terms of Use and Privacy Policy" checkbox.',-1),ta=e("li",null,'Click on the "Register" button.',-1),na=e("p",null,"Once verified, you will be redirected to the login page. You will also receive a welcome email.",-1),ia=e("h2",{id:"password-reset",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#password-reset","aria-hidden":"true"},"#"),a(" Password Reset")],-1),oa=e("p",null,[e("img",{src:r,alt:"Forgot password"})],-1),sa=e("p",null,"If you have forgotten your password, follow these steps to reset it:",-1),ra={href:"https://www.lcda.space/auth/forgot_password",target:"_blank",rel:"noopener noreferrer"},la=e("li",null,"Enter the email address associated with your account.",-1),da=e("li",null,'Click on the "Next" button.',-1),ca=i('<p>If the email address is registered, you will receive an OTP (One Time Password) email to the provided email address.</p><p><img src="'+d+'" alt="Reset passowrd"></p><p>Use the OTP to reset your password by following these steps:</p><ol><li>Enter the OTP received in your email.</li><li>Enter your new password as per the requirements listed on the page.</li><li>Click on the &quot;Reset&quot; button.</li></ol><p>If the password reset is successful, you will be redirected to the login page with a message indicating the success of the password reset. You will also receive a confirmation email at the same time.</p><h1 id="my-data" tabindex="-1"><a class="header-anchor" href="#my-data" aria-hidden="true">#</a> My Data</h1><p>My Data manages data files, allowing you to upload, preview and download data. The platform provides public datasets <code>ProgAssign.csv</code>, <code>iris.csv</code> and <code>wine.csv</code> for all users. You can also upload your own data files.</p>',7),ha=e("p",null,[a("The "),e("code",null,"ProgAssign.csv"),a(" dataset contains 514 student records, including grades for five courses and student programme. Please note that the data in the "),e("code",null,"ProgAssign.csv"),a(" dataset content is constructed by the LCDA team and does not represent real-world data.")],-1),pa=e("p",null,[a("The "),e("code",null,"iris.csv"),a(" dataset contains information on 150 iris flowers, including sepal length, sepal width, petal length, petal width, and variety.")],-1),ua=e("p",null,[a("The "),e("code",null,"wine.csv"),a(" dataset contains information on 178 wine samples, including alcohol, malic acid, ash, alcalinity of ash, magnesium, total phenols, flavanoids, nonflavanoid phenols, proanthocyanins, color intensity, hue, OD280/OD315 of diluted wines, and proline.")],-1),ma=e("code",null,"iris.csv",-1),ga=e("code",null,"wine.csv",-1),fa={href:"https://archive.ics.uci.edu/ml/index.php",target:"_blank",rel:"noopener noreferrer"},ba=i('<h2 id="upload-file" tabindex="-1"><a class="header-anchor" href="#upload-file" aria-hidden="true">#</a> Upload File</h2><p>Once logged in, click <code>Choose File</code> and select the file you need to upload, or drag the file from the folder into the <code>Select File</code> option box. Click <code>Upload</code> after choosing the file, then you can see the files you have uploaded in the file list below.</p><ul><li>Upload one file once</li><li>Support file format of <code>.xlsx</code>, <code>.xls</code> and <code>.csv</code></li><li>File size cannot exceed 3MB</li></ul><p><img src="'+c+'" alt="my_data_upload"></p><h2 id="file-actions" tabindex="-1"><a class="header-anchor" href="#file-actions" aria-hidden="true">#</a> File Actions</h2><p>In the file list, you can preview, download and delete files.</p><ul><li>View: You can view <strong>any</strong> file in the Excel view on the right</li><li>Download: You can download <strong>any</strong> file locally</li><li>Delete: You can delete <strong>only</strong> files uploaded or created by yourself</li></ul><blockquote><p>When you use <a href="#data-processing"><strong>Data Processing</strong></a>, processed files will be created automatically and added to the file list . If you try to delete a file involved in a <strong>Data Processing</strong> project, you will receive a warning. You will then be able to decide whether or not to proceed with the deletion operation.</p></blockquote><p><img src="'+h+'" alt="my_data_action"></p><h1 id="data-processing" tabindex="-1"><a class="header-anchor" href="#data-processing" aria-hidden="true">#</a> Data Processing</h1><p>Data processing is a crucial step in analyzing experimental data using LCDA. Data collected from experiments may contain various issues, such as noise, skewness, and outliers, which may affect the accuracy and reliability of the results. Therefore, it is important to process the data before analysis.</p><p>This chapter will guide you through the steps of data processing. Whether you are a novice or an experienced user, this chapter provides valuable information and guidance to help you obtain accurate and reliable results using LCDA.</p><h2 id="data-processing-projects" tabindex="-1"><a class="header-anchor" href="#data-processing-projects" aria-hidden="true">#</a> Data Processing Projects</h2><h3 id="create-a-new-project" tabindex="-1"><a class="header-anchor" href="#create-a-new-project" aria-hidden="true">#</a> Create a new project</h3><p>Before beginning data processing in LCDA, you will need to create a new data processing project. This can be done by clicking on the <code>NEW PROCESSING</code> button located in the upper right corner of the <code>Data Processing</code> interface.</p><p><img src="'+A+'" alt=""></p><p>In the pop-up window, you will need to select a dataset (Want to upload your own dataset? Please refer to the <a href="#my-data">My Data</a> user manual to learn how to upload a dataset). Then click on the <code>START PROCESSING</code> button in the lower right corner to start data processing. The system will automatically create a data processing project for you.</p><p>Here we use the <code>iris.csv</code> dataset to demonstrate the process of data processing.</p><p><img src="'+C+'" alt=""></p><h3 id="continue-editing-a-project" tabindex="-1"><a class="header-anchor" href="#continue-editing-a-project" aria-hidden="true">#</a> Continue editing a project</h3><p>If you have already created a data processing project, the data processing interface will list all of your data processing projects. You can click on the <code>EDIT</code> button on the right to continue editing an existing data processing project.</p><p><img src="'+D+'" alt=""></p><h3 id="delete-a-project" tabindex="-1"><a class="header-anchor" href="#delete-a-project" aria-hidden="true">#</a> Delete a project</h3><p>If you no longer need a data processing project, you can click on the <code>DELETE</code> button on the right to delete the project.</p><blockquote><p><strong>Note</strong>: Deleting data processing items is a permanent operation and cannot be recovered after deletion. This also deletes the dataset generated by the last run in the project. Please make sure you have saved the data you need before deleting the project.</p></blockquote><p><img src="'+S+'" alt=""></p><h2 id="data-processing-steps" tabindex="-1"><a class="header-anchor" href="#data-processing-steps" aria-hidden="true">#</a> Data Processing Steps</h2><ol><li><p>After clicking the <code>EDIT</code> button or creating a new data processing project, the data processing interface is displayed. From here, you can work with the data.</p><p><img src="'+I+'" alt=""></p><p>In the data processing interface, you will find a list of data processing algorithms on the left-hand side. You can select the algorithm you want to use by clicking on it, and then set the parameters of the algorithm in the pop-up panel. The specific parameters for each algorithm may vary, so please refer to the <a href="#data-processing-algorithms">Data Processing Algorithms</a> for more information on how to set them.</p><p><img src="'+N+'" alt=""></p></li><li><p>Here, we will demonstrate the process of using the <code>Outlier handling</code> algorithm as an example. Once you have selected the algorithm and set the parameters, you can click on the <code>Start processing</code> button located in the lower right corner of the panel to initiate the algorithm.</p><p><img src="'+L+'" alt=""></p></li><li><p>Once the algorithm has completed processing the data, the output will be displayed on the right-hand side of the interface.</p><p><img src="'+P+'" alt=""></p></li><li><p>At the same time, the processed dataset will be saved and added to your list of datasets. To view or download your new dataset, you can navigate to the <code>My Data</code> page.</p><p><img src="'+E+'" alt=""></p></li></ol><h2 id="data-processing-algorithms" tabindex="-1"><a class="header-anchor" href="#data-processing-algorithms" aria-hidden="true">#</a> Data Processing Algorithms</h2><h3 id="outlier-handling" tabindex="-1"><a class="header-anchor" href="#outlier-handling" aria-hidden="true">#</a> Outlier Handling</h3><h4 id="description" tabindex="-1"><a class="header-anchor" href="#description" aria-hidden="true">#</a> Description</h4><p>Outlier handling algorithms are used to identify and handle outliers in a dataset. In statistics, an outlier is a data point that significantly differs from other observations, and may be caused by experimental error or other factors. Outliers can cause serious problems in statistical analysis and can affect the accuracy and reliability of results. Therefore, outlier handling algorithms are essential for identifying and dealing with these problematic data points. These algorithms can help improve the quality of the dataset and ultimately lead to more accurate and reliable analysis results.</p>',32),_a={href:"https://en.wikipedia.org/wiki/Outlier",target:"_blank",rel:"noopener noreferrer"},va=e("h4",{id:"parameters",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#parameters","aria-hidden":"true"},"#"),a(" Parameters")],-1),ya=e("code",null,"Detection method",-1),wa={href:"https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule",target:"_blank",rel:"noopener noreferrer"},ka={href:"https://en.wikipedia.org/wiki/Interquartile_range",target:"_blank",rel:"noopener noreferrer"},xa={href:"https://en.wikipedia.org/wiki/Median_absolute_deviation",target:"_blank",rel:"noopener noreferrer"},Ta=e("li",null,[e("code",null,"Processing method"),a(": Outlier processing method. Currently supports "),e("code",null,"set to null"),a(", "),e("code",null,"set to mean"),a(", and "),e("code",null,"set to median"),a(" three methods.")],-1),Aa=e("h3",{id:"missing-value-handling",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#missing-value-handling","aria-hidden":"true"},"#"),a(" Missing Value Handling")],-1),Ca=e("h4",{id:"description-1",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#description-1","aria-hidden":"true"},"#"),a(" Description")],-1),Da=e("p",null,"Missing data can result in biased or inaccurate results if not handled properly. Missing value handling algorithms can be used to impute the missing data with reasonable estimates, based on statistical methods such as mean imputation, median imputation. These methods can help to reduce the bias and improve the accuracy of statistical analysis.",-1),Sa={href:"https://en.wikipedia.org/wiki/Missing_data",target:"_blank",rel:"noopener noreferrer"},Ia=i('<h4 id="parameters-1" tabindex="-1"><a class="header-anchor" href="#parameters-1" aria-hidden="true">#</a> Parameters</h4><ul><li><code>identification method</code>: Missing value detection method. Currently supports <code>empty</code>, <code>space</code>, <code>None</code> and <code>Non-numeric</code> four methods.</li><li><code>filling method</code>: missing value processing method. Currently supports <code>mean</code>, <code>median</code>, and <code>mode</code> three methods.</li></ul><h3 id="tail-shrinkage-and-truncation-processing" tabindex="-1"><a class="header-anchor" href="#tail-shrinkage-and-truncation-processing" aria-hidden="true">#</a> Tail Shrinkage and Truncation Processing</h3><h4 id="description-2" tabindex="-1"><a class="header-anchor" href="#description-2" aria-hidden="true">#</a> Description</h4><p>Tail shrinkage and truncation processing algorithms are used to shrink the tails of a distribution. This can be useful when the tails of a distribution are too long, which can cause problems in statistical analysis. These algorithms can help to reduce the bias and improve the accuracy of statistical analysis.</p>',5),Na={href:"https://en.wikipedia.org/wiki/Truncation_(statistics)",target:"_blank",rel:"noopener noreferrer"},La={href:"https://en.wikipedia.org/wiki/Shrinkage_(statistics)",target:"_blank",rel:"noopener noreferrer"},Pa=i('<h4 id="parameters-2" tabindex="-1"><a class="header-anchor" href="#parameters-2" aria-hidden="true">#</a> Parameters</h4><ul><li><code>method_selection</code>: Tail shrinkage and truncation processing method. Currently supports <code>tail_shrinkage</code> and <code>tail_truncation</code> two methods.</li><li><code>upper_limit</code>: Upper limit of the tail shrinkage and truncation processing. Data types are numeric.</li><li><code>lower_limit</code>: Lower limit of the tail shrinkage and truncation processing. Data types are numeric.</li><li><code>processing_method</code>: Tail shrinkage and truncation processing method. Currently supports <code>delete_value</code> and <code>delete_row</code> two methods.</li></ul><h3 id="data-transformation" tabindex="-1"><a class="header-anchor" href="#data-transformation" aria-hidden="true">#</a> Data Transformation</h3><h4 id="description-3" tabindex="-1"><a class="header-anchor" href="#description-3" aria-hidden="true">#</a> Description</h4><p>In statistics, data transformation is the application of a deterministic mathematical function to each point in a data setâ€”that is, each data point z is replaced with the transformed value y = f(z), where f is a function. Transforms are usually applied so that the data appear to more closely meet the assumptions of a statistical inference procedure that is to be applied, or to improve the interpretability or appearance of graphs.</p>',5),Ea={href:"https://en.wikipedia.org/wiki/Data_transformation_(statistics)",target:"_blank",rel:"noopener noreferrer"},qa=e("h4",{id:"parameters-3",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#parameters-3","aria-hidden":"true"},"#"),a(" Parameters")],-1),Ma=e("code",null,"transform_method",-1),Oa={href:"https://en.wikipedia.org/wiki/Fast_Fourier_transform",target:"_blank",rel:"noopener noreferrer"},Ra=e("h3",{id:"dimension-reduction",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#dimension-reduction","aria-hidden":"true"},"#"),a(" Dimension Reduction")],-1),ja=e("h4",{id:"description-4",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#description-4","aria-hidden":"true"},"#"),a(" Description")],-1),Fa=e("p",null,"Data dimensionality reduction is the process of reducing the number of dimensions or variables in a high-dimensional dataset, while retaining the essential information. The aim is to simplify the dataset and eliminate the irrelevant or redundant variables, making it easier to process and analyze. The process involves transforming the data into a lower-dimensional space, while still preserving the key characteristics of the data. This technique is particularly useful for dealing with large datasets where high dimensionality can lead to issues with computational efficiency and overfitting.",-1),za={href:"https://en.wikipedia.org/wiki/Dimensionality_reduction",target:"_blank",rel:"noopener noreferrer"},Wa=e("h4",{id:"parameters-4",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#parameters-4","aria-hidden":"true"},"#"),a(" Parameters")],-1),Ya=e("code",null,"method",-1),Ba={href:"https://en.wikipedia.org/wiki/Principal_component_analysis",target:"_blank",rel:"noopener noreferrer"},Ua={href:"https://en.wikipedia.org/wiki/Linear_discriminant_analysis",target:"_blank",rel:"noopener noreferrer"},Ga=e("li",null,[e("code",null,"n_components"),a(": Number of components to keep. Data types are numeric.")],-1),Ha=e("h3",{id:"sample-balancing",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#sample-balancing","aria-hidden":"true"},"#"),a(" Sample Balancing")],-1),Ka=e("h4",{id:"description-5",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#description-5","aria-hidden":"true"},"#"),a(" Description")],-1),Va=e("p",null,"Sample balance refers to the process of adjusting the number of samples in each category of a dataset so that they are more evenly distributed. This is important in machine learning and statistical analysis because imbalanced datasets can lead to biased results, especially when dealing with rare events or minority classes. By balancing the samples, we can improve the performance and accuracy of the algorithms that use the dataset.",-1),$a={href:"https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis",target:"_blank",rel:"noopener noreferrer"},Ja=e("h4",{id:"parameters-5",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#parameters-5","aria-hidden":"true"},"#"),a(" Parameters")],-1),Za=e("code",null,"balancing_method",-1),Qa=e("code",null,"undersample",-1),Xa={href:"https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html",target:"_blank",rel:"noopener noreferrer"},et=e("code",null,"oversample",-1),at={href:"https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html",target:"_blank",rel:"noopener noreferrer"},tt=e("code",null,"combined",-1),nt={href:"https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html",target:"_blank",rel:"noopener noreferrer"},it=e("h3",{id:"normalization",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#normalization","aria-hidden":"true"},"#"),a(" Normalization")],-1),ot=e("h4",{id:"description-6",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#description-6","aria-hidden":"true"},"#"),a(" Description")],-1),st=e("p",null,"The purpose of standardization is to make the dataset easier to compare and analyze. Standardization also helps to remove the units of measurement from the data, making it possible to compare variables that have different units.",-1),rt={href:"https://en.wikipedia.org/wiki/Normalization_(statistics)",target:"_blank",rel:"noopener noreferrer"},lt=e("h4",{id:"parameters-6",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#parameters-6","aria-hidden":"true"},"#"),a(" Parameters")],-1),dt=e("code",null,"Method",-1),ct={href:"https://en.wikipedia.org/wiki/Feature_scaling",target:"_blank",rel:"noopener noreferrer"},ht={href:"https://en.wikipedia.org/wiki/Standard_score",target:"_blank",rel:"noopener noreferrer"},pt=i('<h1 id="data-analysis" tabindex="-1"><a class="header-anchor" href="#data-analysis" aria-hidden="true">#</a> Data Analysis</h1><p>Data Analysis helps you to analyze your data on top of <a href="#data-processing">Data Processing</a>. Data Analysis provides various algorithms and models used in economics, medicine, social science and Machine Learning, etc.</p><p>This chapter will tell you how to analyze data with LCDA, with all the information about the algorithms we provide.</p><h2 id="analysis-steps" tabindex="-1"><a class="header-anchor" href="#analysis-steps" aria-hidden="true">#</a> Analysis Steps</h2><ol><li><p>Click on <code>Data Analysis</code> in the navigation bar above to go to the data analysis page.</p></li><li><p>Once logged in, click on <code>NEW ANALYSIS</code> in the top right corner, here we select the dataset <code>iris.csv</code> and click on <code>START ANALYSING</code> to start the analysis of the data. <img src="'+q+'" alt="data_analysis"><img src="'+M+'" alt="start_analysing"></p></li><li><p>The project page firstly displays the project&#39;s analysis results <code>Analysis results</code> and the algorithm selection area <code>Choose algorithm</code>.</p><p><img src="'+O+'" alt="project_view"></p><p>In the algorithm selection area, the data analysis algorithms and models are classified into several categories. Here we will apply the KNN classification algorithm to the iris dataset, so we click on <code>ML Classification</code> and select <code>K-Nearest Neighbors</code>. A description of the algorithm, the available parameters and the corresponding description will be displayed on the right. <img src="'+R+'" alt="knn"> Once you have configured the parameters, click <code>SUBMIT</code> in the bottom right corner at the end of the page to submit the algorithm and parameters.</p></li><li><p>Once you have submitted your algorithm, you can see the analysis report for the algorithm you have just run in the <code>Analysis results</code> on the left hand side. Click on the report to view it on the right. <img src="'+j+'" alt="result_view"></p></li><li><p>The <code>Print</code> button on the top right of the report provides a full screen view and download of the report.</p></li></ol><h2 id="algorithms" tabindex="-1"><a class="header-anchor" href="#algorithms" aria-hidden="true">#</a> Algorithms</h2><h3 id="comprehensive-evaluation" tabindex="-1"><a class="header-anchor" href="#comprehensive-evaluation" aria-hidden="true">#</a> Comprehensive Evaluation</h3><h4 id="decision-matrix" tabindex="-1"><a class="header-anchor" href="#decision-matrix" aria-hidden="true">#</a> Decision Matrix</h4><p>Decision matrix (or CRITIC weighting method) is an objective weighting method. The idea is to use two indicators, which are contrast intensity and conflictiveness. Contrast intensity is expressed by standard deviation, if the standard deviation of the data is larger, it means more fluctuation, and the weight will be higher; conflict is expressed by correlation coefficient, if the value of correlation coefficient between indicators is larger, it means less conflict, and then its weight will be lower. For the comprehensive evaluation of multiple indicators and multiple objects, decision matrix eliminates the influence of some indicators with strong correlation and reduces the overlap of information between indicators, which is more conducive to obtaining credible evaluation results.</p><h5 id="input-and-output" tabindex="-1"><a class="header-anchor" href="#input-and-output" aria-hidden="true">#</a> Input and Output</h5><ul><li><p>Input: at least two or more quantitative variables (can be positive or negative, but do not standardize)</p></li><li><p>Output: Enter the values of the weights corresponding to the quantitative variables</p></li></ul><h5 id="example-case" tabindex="-1"><a class="header-anchor" href="#example-case" aria-hidden="true">#</a> Example Case</h5><p><img src="'+o+'" alt="decision_matrix"></p><h3 id="descriptive-statistics" tabindex="-1"><a class="header-anchor" href="#descriptive-statistics" aria-hidden="true">#</a> Descriptive Statistics</h3><h4 id="normality-test" tabindex="-1"><a class="header-anchor" href="#normality-test" aria-hidden="true">#</a> Normality Test</h4><p>A normality test is any statistical test for determining whether a data sample comes from a normal distribution.</p><h5 id="input-and-output-1" tabindex="-1"><a class="header-anchor" href="#input-and-output-1" aria-hidden="true">#</a> Input and Output</h5><ul><li>Input: One or more quantitative variables</li><li>Output: The results of the model test (with data satisfying/not satisfying a normal distribution)</li></ul><h5 id="example-case-1" tabindex="-1"><a class="header-anchor" href="#example-case-1" aria-hidden="true">#</a> Example Case</h5><p><img src="'+o+'" alt="decision_matrix"></p><h3 id="questionnaire-analysis" tabindex="-1"><a class="header-anchor" href="#questionnaire-analysis" aria-hidden="true">#</a> Questionnaire Analysis</h3><h4 id="reliability-analysis" tabindex="-1"><a class="header-anchor" href="#reliability-analysis" aria-hidden="true">#</a> Reliability Analysis</h4><p>Reliability analysis is mainly used to examine the stability and consistency of the results measured by the scale in the questionnaire, that is, to test whether the scale samples in the questionnaire are reliable and credible. The scale question type is the option of the question, which is set according to the level of statement. For example, our love for mobile phones has changed from very fond of to dislike. The most famous scale in the scale is the Likert 5-level scale. The options of this scale are mainly divided into &quot;strongly agree&quot;, &quot;agree&quot;, &quot;not sure&quot;, &quot;disagree&quot;, &quot;very disagree&quot; five answers, recorded as 5, 4, 3, 2, 1 respectively.</p><h5 id="input-and-output-2" tabindex="-1"><a class="header-anchor" href="#input-and-output-2" aria-hidden="true">#</a> Input and Output</h5><ul><li>Input: At least two or more quantitative variables or ordered fixed categories of variables, generally requiring data to be scale data</li><li>Output: Reliability of the reliability of the collection questionnaire scales</li></ul><h5 id="example-case-2" tabindex="-1"><a class="header-anchor" href="#example-case-2" aria-hidden="true">#</a> Example Case</h5><p><img src="'+F+'" alt="realiability_test"></p><h3 id="econometric-models" tabindex="-1"><a class="header-anchor" href="#econometric-models" aria-hidden="true">#</a> Econometric Models</h3><h4 id="adf-test" tabindex="-1"><a class="header-anchor" href="#adf-test" aria-hidden="true">#</a> ADF Test</h4><p>When using many time series models, such as ARMA and ARIMA, the time series is required to be stationary, so generally when studying a period of time series, the first step is to perform a stationarity test. In addition to the method of visual inspection, in addition The more commonly used strict statistical test method is the ADF test, also known as the unit root test.</p><h5 id="input-and-output-3" tabindex="-1"><a class="header-anchor" href="#input-and-output-3" aria-hidden="true">#</a> Input and Output</h5><ul><li>Input: 1 quantitative variable for time series data</li><li>Output: Sequence data is smoothed at several orders of differencing</li></ul><h5 id="example-case-3" tabindex="-1"><a class="header-anchor" href="#example-case-3" aria-hidden="true">#</a> Example Case</h5><p><img src="'+z+'" alt="ADF_test"></p><h3 id="medical-statistical-model" tabindex="-1"><a class="header-anchor" href="#medical-statistical-model" aria-hidden="true">#</a> Medical Statistical Model</h3><h4 id="bland-altman-method" tabindex="-1"><a class="header-anchor" href="#bland-altman-method" aria-hidden="true">#</a> Bland-Altman Method</h4><p>A method for visual consistency checking. Its principle is an intuitive method to draw graphs using the difference, mean and 95% consistency (LoA) of the results of the two methods, so as to determine whether the results of the two methods are consistent.</p><h5 id="input-and-output-4" tabindex="-1"><a class="header-anchor" href="#input-and-output-4" aria-hidden="true">#</a> Input and Output</h5><ul><li>Input: Two quantitative variables representing the two methods</li><li>Output: Bland-Altman graph and whether there is consistency in the approach.</li></ul><h5 id="example-case-4" tabindex="-1"><a class="header-anchor" href="#example-case-4" aria-hidden="true">#</a> Example Case</h5><p><img src="'+W+'" alt="Bland_Altman"></p><h3 id="ml-classification" tabindex="-1"><a class="header-anchor" href="#ml-classification" aria-hidden="true">#</a> ML Classification</h3><h4 id="k-nearest-neighbors" tabindex="-1"><a class="header-anchor" href="#k-nearest-neighbors" aria-hidden="true">#</a> K-Nearest Neighbors</h4><p>K-Nearest Neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions).</p><h5 id="input-and-output-5" tabindex="-1"><a class="header-anchor" href="#input-and-output-5" aria-hidden="true">#</a> Input and Output</h5><ul><li>Input: The variables as features are fixed or quantitative variables, and the variable as target is a fixed variable. <!--content here need check--></li><li>Output: The classification results of the model and the evaluation effect of the model classification.</li></ul><h5 id="parameter-options" tabindex="-1"><a class="header-anchor" href="#parameter-options" aria-hidden="true">#</a> Parameter Options</h5>',47),ut=e("li",null,"Data Shuffling: Whether to shuffle data randomly",-1),mt=e("li",null,"Training Ratio: Ratio of training data to the whole dataset",-1),gt=e("li",null,"Cross Validation: The number of equal sized subsamples randomly partitioned from the original sample. Each subsample will be retained as the validation data for testing the model, and the remaining subsamples will be used as training data",-1),ft=e("li",null,"Number of Neighbors: Number of neighbors to use",-1),bt=e("li",null,[a("Weights: Weight function used in prediction. Selection values: "),e("ul",null,[e("li",null,"uniform: Uniform weights. All points in each neighborhood are weighted equally"),e("li",null,"distance: Weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away")])],-1),_t=e("li",null,"auto: will attempt to decide the most appropriate algorithm based on the values passed",-1),vt={href:"https://en.wikipedia.org/wiki/Ball_tree",target:"_blank",rel:"noopener noreferrer"},yt=e("code",null,"BallTree",-1),wt=e("code",null,"KDTree",-1),kt={href:"https://en.wikipedia.org/wiki/K-d_tree",target:"_blank",rel:"noopener noreferrer"},xt=e("li",null,"brute: will use a brute-force search Note: fitting on sparse input will override the setting of this parameter, using brute force",-1),Tt=e("li",null,[a("Leaf Size: Leaf size passed to "),e("code",null,"BallTree"),a(" or "),e("code",null,"KDTree"),a(". This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem")],-1),At=e("li",null,"P: Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used",-1),Ct=i('<h5 id="example-case-5" tabindex="-1"><a class="header-anchor" href="#example-case-5" aria-hidden="true">#</a> Example Case</h5><p><img src="'+Y+'" alt="k_nn"></p><h4 id="svm-classification" tabindex="-1"><a class="header-anchor" href="#svm-classification" aria-hidden="true">#</a> SVM classification</h4><p>Support vector machine (SVM) is a class of generalised linear classifiers that perform binary classification of data in a supervised learning fashion, with a decision boundary that is a maximum margin hyperplane solved for the learned samples.</p><h5 id="input-and-output-6" tabindex="-1"><a class="header-anchor" href="#input-and-output-6" aria-hidden="true">#</a> Input and Output</h5><ul><li>Input: The variables as features are fixed or quantitative variables, and the variable as target is a fixed variable.</li><li>Output: The classification results of the model and the evaluation effect of the model classification.</li></ul><h5 id="parameter-options-1" tabindex="-1"><a class="header-anchor" href="#parameter-options-1" aria-hidden="true">#</a> Parameter Options</h5><ul><li>Data Shuffling: Whether to shuffle data randomly</li><li>Training Ratio: Ratio of training data to the whole dataset</li><li>Cross Validation: The number of equal sized subsamples randomly partitioned from the original sample. Each subsample will be retained as the validation data for testing the model, and the remaining subsamples will be used as training data</li><li>Penalty Coefficient: Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty</li><li>Kernel Algorithm: Specifies the kernel type to be used in the algorithm</li><li>Error Convergence Conditions: Tolerance for stopping criterion</li><li>Maximum Number of Iterations: Hard limit on iterations within solver, or -1 for no limit</li></ul><h5 id="example-case-6" tabindex="-1"><a class="header-anchor" href="#example-case-6" aria-hidden="true">#</a> Example Case</h5><p><img src="'+B+'" alt="svm"></p><h3 id="decision-tree" tabindex="-1"><a class="header-anchor" href="#decision-tree" aria-hidden="true">#</a> Decision Tree</h3><p>A decision tree is a flowchart-like structure in which each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes).</p><h4 id="input-and-output-7" tabindex="-1"><a class="header-anchor" href="#input-and-output-7" aria-hidden="true">#</a> Input and Output</h4><ul><li>Input: The variables as features are fixed or quantitative variables, and the variable as target is a fixed variable.</li><li>Output: The classification results of the model and the evaluation effect of the model classification.</li></ul><h4 id="parameter-options-2" tabindex="-1"><a class="header-anchor" href="#parameter-options-2" aria-hidden="true">#</a> Parameter Options</h4><ul><li>Data Shuffling: Whether to shuffle data randomly</li><li>Training Ratio: Ratio of training data to the whole dataset</li><li>Cross Validation: The number of equal sized subsamples randomly partitioned from the original sample. Each subsample will be retained as the validation data for testing the model, and the remaining subsamples will be used as training data</li><li>Criterion: The function to measure the quality of a split. Supported criteria are: <ul><li>gini: for the Gini impurity</li><li>entropy: for the Shannon information gain</li></ul></li><li>Splitter: The strategy used to choose the split at each node. Supported strategies: <ul><li>best: choose the best split</li><li>random: choose the best random split</li></ul></li><li>Min Samples Split: The minimum number of samples required to split an internal node: <ul><li>If int, then consider <code>Min Samples Split</code> as the minimum number.</li><li>If float, then <code>Min Samples Split</code> is a fraction and <code>ceil(Min Samples Split * n_samples)</code> are the minimum number of samples for each split.</li></ul></li><li>Min Samples Leaf: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least <code>Min Samples Leaf</code> training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression. <ul><li>If int, then consider <code>Min Samples Leaf</code> as the minimum number.</li><li>If float, then <code>Min Samples Leaf</code> is a fraction and <code>ceil(Min Samples Leaf* n_samples)</code> are the minimum number of samples for each node. .. versionchanged:: 0.18 Added float values for fractions.</li></ul></li><li>Max Depth: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than <code>Min Samples Split</code> samples.</li><li>Max Leaf Nodes: Grow a tree with <code>Max Leaf Nodes</code> in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</li></ul><h4 id="example-case-7" tabindex="-1"><a class="header-anchor" href="#example-case-7" aria-hidden="true">#</a> Example Case</h4><p><img src="'+U+'" alt="decision_tree"></p><h1 id="forum" tabindex="-1"><a class="header-anchor" href="#forum" aria-hidden="true">#</a> Forum</h1><p>The LCDA forum is a platform designed to promote user-friendly communication. Users are encouraged to post questions and comments, which can be answered and discussed by other users.</p><p>If you have any questions or suggestions about LCDA, please feel free to post them in the forum. However, to ensure effective communication, all posts and comments must be written in English.</p><p>To maintain a positive and respectful atmosphere in the forum, please refrain from posting the following types of content:</p><ul><li>Non-English content.</li><li>Meaningless content, such as random characters or single words or phrases.</li></ul>',23),Dt={href:"https://www.lcda.space/legal/terms#ugc",target:"_blank",rel:"noopener noreferrer"},St=i('<h2 id="interface" tabindex="-1"><a class="header-anchor" href="#interface" aria-hidden="true">#</a> Interface</h2><p>When you visit a forum page, you can view all posts and their corresponding comments. Each post has a title, author, release time, modification time, and content. You can also see the comments of each post.</p><p>Posts and comments are sorted from newest to oldest based on modification time and creation time respectively.</p><p>If a post or comment has been modified after it was initially created, its modification time will also be updated.</p><p><img src="'+p+'" alt="Forum index page"></p><h2 id="post" tabindex="-1"><a class="header-anchor" href="#post" aria-hidden="true">#</a> Post</h2><p>After logging in, you can create a new post by clicking the &quot;New Post&quot; button located at the bottom right corner of the forum page.</p><p><img src="'+u+'" alt="Forum post"></p><p>This will redirect you to a page where you can fill in the title and text of your post. Once you are done, simply click on the <code>SUBMIT</code> button to publish your post.</p><p><img src="'+m+'" alt="Forum post"></p><h2 id="comment" tabindex="-1"><a class="header-anchor" href="#comment" aria-hidden="true">#</a> Comment</h2><p>After logging in, you can write comments below the body of all posts on the main forum page. To do so, simply enter your comment in the provided text box. Once you have finished writing your comment,click the <code>SUBMIT</code> button to post it.</p><p><strong>Please note that comments can only be added below the body of the post, and cannot be added below another comment. Additionally, once a comment is published, it cannot be edited.</strong></p><p><img src="'+g+'" alt="Forum post"></p><h2 id="edit-post" tabindex="-1"><a class="header-anchor" href="#edit-post" aria-hidden="true">#</a> Edit Post</h2><p>When you are logged in, you can edit your own posts on the main forum page by clicking the <code>EDIT</code> button to the right of the post. This will allow you to modify the title and body of the post.</p><p><img src="'+f+'" alt="Forum post"></p><p>On the page for editing a post, you can modify the title and text of the post. Once you have made the desired changes, click the <code>SUBMIT</code> button to update the post. Alternatively, you can click the <code>DELETE</code> button to remove the post.</p><p><strong>It is important to note that deleting a post is an irreversible action, and you will not be able to recover a deleted post. Additionally, once a post is deleted, all comments associated with the post will also be removed.</strong></p><p><img src="'+b+'" alt="Forum post"></p><h2 id="delete-comment" tabindex="-1"><a class="header-anchor" href="#delete-comment" aria-hidden="true">#</a> Delete Comment</h2><p>When you are logged in, a <code>DELETE</code> button will appear to the right of each comment that you have posted on the main forum page. Clicking on the <code>DELETE</code> button will allow you to delete the comment.</p><p><strong>Please note that once you delete a comment, you will not be able to restore the deleted comment.</strong></p><p><img src="'+_+'" alt="Forum post"></p><h2 id="violations" tabindex="-1"><a class="header-anchor" href="#violations" aria-hidden="true">#</a> Violations</h2><p>Below are some examples of posts that violate the forum rules. If you come across any such content, please report it to the LCDA team at <a href="mailto:lcda.team.2023@gmail.com">lcda.team.2023@gmail.com</a> immediately.</p><h3 id="non-english-content" tabindex="-1"><a class="header-anchor" href="#non-english-content" aria-hidden="true">#</a> Non-English Content</h3><p><img src="'+v+'" alt="Forum post"></p><h3 id="meaningless-content" tabindex="-1"><a class="header-anchor" href="#meaningless-content" aria-hidden="true">#</a> Meaningless Content</h3><p><img src="'+G+'" alt="Forum post"></p><h3 id="profanity-content" tabindex="-1"><a class="header-anchor" href="#profanity-content" aria-hidden="true">#</a> Profanity Content</h3><p>Test content:</p><p><img src="'+H+'" alt="Forum post"></p><p>Filtered content:</p><p><img src="'+K+'" alt="Forum post"></p><h1 id="node-editor" tabindex="-1"><a class="header-anchor" href="#node-editor" aria-hidden="true">#</a> Node Editor</h1><p>Node Editor is a fully graphical data processing tool. Here you can apply multiple data processing methods to multiple datasets on a single page at the same time.</p><h2 id="how-to-use" tabindex="-1"><a class="header-anchor" href="#how-to-use" aria-hidden="true">#</a> How to Use</h2><ol><li><p>Once logged in, click on <strong>Node Editor</strong> from the top navigation bar to access the node editor interface.<!--can add link--></p></li><li><p>Right-click on any blank space to call out a list of nodes and left-click on the node name to create the node.</p><p><img src="'+y+'" alt="creating_nodes"></p><p><img src="'+V+'" alt="creation_result"></p><p>The nodes to create can be divided functionally into three categories: data nodes, processing nodes and output nodes. For a more detailed description of the nodes see <a href="#list-of-nodes">List of Nodes</a>.</p></li><li><p>When establishing a processing flow, there are several points to note:</p><ul><li><p>The input interface of each node is on the left, and the output interface is on the right</p></li><li><p>One <strong>input</strong> interface can only be connected to <strong>one</strong> node, but one output interface can be connected to multiple nodes, which means that branches can exist in a flow</p></li><li><p>At least one output node must be included in a flow to activate it. Otherwise, the flow will not run</p></li></ul><p>Next, we will use a Data Node, a Column Selection Node, a Normalization Node, and an End Process Node to build a simple data processing flow</p><p><img src="'+$+'" alt="process_preparation"></p><p>Next, we will connect the four nodes in series to activate them all, and select the iris.csv dataset from the public dataset for processing in node Data. It can be seen that the column names of iris.csv have been displayed in the ColumnSelectionNode</p><p><img src="'+J+'" alt="process_1step"></p><p>In the ColumnSelectionNode, we fill in <code>sepal.length</code>, select the normalization method as Min-Max in the Normalization Node, set the new filename as <code>sepal.length-minmax,</code> and finally connect Data and Normalization to complete the processing flow.</p><p>The processing result will be uploaded to your file space as <code>sepal.length-minmax.csv</code>, which can be viewed in <code>My Data</code>.</p><p><img src="'+Z+'" alt="process_2step"></p></li></ol><h2 id="list-of-nodes" tabindex="-1"><a class="header-anchor" href="#list-of-nodes" aria-hidden="true">#</a> List of Nodes</h2><h3 id="data-nodes" tabindex="-1"><a class="header-anchor" href="#data-nodes" aria-hidden="true">#</a> Data Nodes</h3><ul><li><p>Data Node</p><p>The Data Node provides the data source for processing in the editor. A drop-down option it has will display the datasets you currently have, including those you have uploaded and those generated by processing tasks.</p></li><li><p>Column Selection Node</p><p>The Column Selection Node is used to select columns from a dataset. When the Column Selection Node is correctly activated in the node editor, a line of text will appear between the input and output interfaces, showing all the columns in the received dataset. The input field below the display row is used to select the columns you want to output for processing, and column names are separated by commas.</p></li></ul><h3 id="output-nodes" tabindex="-1"><a class="header-anchor" href="#output-nodes" aria-hidden="true">#</a> Output Nodes</h3><p>An output node is a node that only has an input interface but no output interface. In the node editor, a process <strong>must</strong> contain <strong>at least one</strong> output node to activate the process. Otherwise, <strong>any</strong> calculations or operations in the flow will not be effective.</p><ul><li><p>End Node</p><p>The End Node is the most basic output node, it is also the most recommended one. It does not have any output display, but only marks the end of a branch in the process.</p></li><li><p>Display Node</p><p>By connecting a node to the Display Node on the basis of the End Node, the output of the current node can be displayed. The storage structure of most node output files in the editor can be used to check whether a branch in the process has run successfully. However, it is not recommended to use only the Display Node without the End Node.</p></li></ul><blockquote><p>Tips:</p><p>We do not recommend using Display Node alone because its display is not synchronous. If you use Display Node instead of End Node alone, but do not see any display content after connection, it does not necessarily mean that the operation in the current process or branch has failed. If you have done the above operation, you need to create a new node in the node editor to refresh the display.</p></blockquote><h3 id="processing-nodes" tabindex="-1"><a class="header-anchor" href="#processing-nodes" aria-hidden="true">#</a> Processing Nodes</h3><p>The current Node Editor contains 7 processing nodes, which have the same processing methods as those in Data Processing, and each node is named after a data processing method. Each processing node will include:</p><ul><li>A data input interface, to connect Data Node for input dataset</li><li>A column input interface, to connect Column Selection Node for input columns to process</li><li>A text input, to define name of processed dataset (No extension names needed)</li><li>A output interface, to output processed dataset</li><li>Some parameter options to select for the processing algorithm</li></ul>',49);function It(Nt,Lt){const t=k("ExternalLinkIcon");return x(),T("div",null,[X,ee,ae,te,e("p",null,[e("a",ne,[a("lcda.space"),n(t)])]),ie,e("p",null,[a("This user manual is also available online at "),e("a",oe,[a("guide.lcda.space"),n(t)]),a(".")]),se,re,le,de,ce,e("p",null,[a("The LCDA platform was developed with the aim of addressing the challenges faced by beginners when dealing with the complicated terminologies associated with artificial intelligence. The LCDA team, comprised of members who took an "),e("a",he,[a("introductory course in Artificial Intelligence"),n(t)]),a(" during their undergraduate Year 1 studies, understands the difficulty of learning AI from scratch. To make the process less intimidating for beginners, the team decided to create a website that allows users to explore the world of AI without having to install any software. Currently, the platform is in the demo stage and is continuously being improved to provide a better user experience.")]),pe,e("p",null,[a("LCDA is a Python-based web application that is built using "),e("a",ue,[a("Flask"),n(t)]),a(", making it easily accessible to users through their web browser. Python was chosen as the programming language for this project due to its extensive library of artificial intelligence and data science related packages. This allowed the team to efficiently achieve the project's goals within a limited development timeline.")]),me,e("p",null,[a("The quickest way to use LCDA is to directly visit the "),e("a",ge,[a("official website of LCDA"),n(t)]),a(".")]),e("p",null,[a("However, if you want to deploy your own LCDA, it is essential to ensure that you can create and configure the following instances: "),e("a",fe,[a("Google Cloud Run"),n(t)]),a(", "),e("a",be,[a("Google Cloud Storage"),n(t)]),a(", and a publicly accessible database such as "),e("a",_e,[a("Amazon RDS"),n(t)]),a(".")]),ve,ye,e("ul",null,[e("li",null,[e("p",null,[e("a",we,[a("Miniconda"),n(t)]),a(" v23.1.0+ or "),e("a",ke,[a("Anaconda"),n(t)]),a(" v23.1.0+")])]),e("li",null,[e("p",null,[e("a",xe,[a("Python"),n(t)]),a(" v3.7+ if you use "),Te,a(" virtual environment")])]),e("li",null,[e("p",null,[e("a",Ae,[a("Git"),n(t)]),a(" v2.30+")])]),e("li",null,[e("p",null,[e("a",Ce,[a("Google Cloud Run"),n(t)])])]),e("li",null,[e("p",null,[e("a",De,[a("Google Cloud Storage"),n(t)])])]),e("li",null,[e("p",null,[e("a",Se,[a("Amazon RDS"),n(t)])])])]),Ie,Ne,e("ol",null,[Le,e("li",null,[Pe,Ee,e("ul",null,[e("li",null,[e("p",null,[e("a",qe,[a("Amazon RDS"),n(t)]),a(": LCDA uses Amazon RDS to host the website database. Detailed database configuration tutorials can be found in the "),e("a",Me,[a("official documentation"),n(t)]),a(". However, users can also choose other cloud hosting service providers for their database needs.")])]),e("li",null,[e("p",null,[e("a",Oe,[a("Google Cloud Storage"),n(t)]),a(": LCDA uses Google Cloud Storage as the storage server for the website. Detailed tutorials on using Google Cloud Storage can be found in the "),e("a",Re,[a("official documentation"),n(t)]),a(".")])]),e("li",null,[e("p",null,[e("a",je,[a("Google Cloud Run"),n(t)]),a(": LCDA uses Google Cloud Run to host and deploy the website. A detailed tutorial on using Google Cloud Run can be found in the "),e("a",Fe,[a("official documentation"),n(t)]),a(".")])])]),ze]),We]),e("p",null,[a("You're done! Now you can visit "),e("a",Ye,[a("http://127.0.0.1:5000"),n(t)]),a(" in your browser to access LCDA.")]),Be,e("ol",null,[e("li",null,[e("p",null,[a("Click on the '"),e("a",Ue,[a("Login"),n(t)]),a("' button or be redirected to the login page.")])]),Ge,He]),Ke,Ve,$e,Je,e("ol",null,[e("li",null,[a("Click on the '"),e("a",Ze,[a("Sign Up"),n(t)]),a("' button.")]),Qe,e("li",null,[a("Read the "),e("a",Xe,[a("Terms and Conditions"),n(t)]),a(" and "),e("a",ea,[a("Privacy Policy"),n(t)]),a(" carefully.")]),aa,ta]),na,ia,oa,sa,e("ol",null,[e("li",null,[a("Navigate to the "),e("a",ra,[a("Account Recovery"),n(t)]),a(" page.")]),la,da]),ca,e("blockquote",null,[ha,pa,ua,e("p",null,[a("The "),ma,a(" and "),ga,a(" datasets are sourced from the "),e("a",fa,[a("UCI Machine Learning Repository"),n(t)]),a(".")])]),ba,e("blockquote",null,[e("p",null,[e("a",_a,[a("Outlier - Wikipedia"),n(t)])])]),va,e("ul",null,[e("li",null,[ya,a(": Outlier detection method. currently supported "),e("a",wa,[a("3-sigma"),n(t)]),a(", "),e("a",ka,[a("IQR"),n(t)]),a(", and "),e("a",xa,[a("MAD"),n(t)]),a(" three methods.")]),Ta]),Aa,Ca,Da,e("blockquote",null,[e("p",null,[e("a",Sa,[a("Missing data - Wikipedia"),n(t)])])]),Ia,e("blockquote",null,[e("p",null,[e("a",Na,[a("Truncation (statistics) - Wikipedia"),n(t)])]),e("p",null,[e("a",La,[a("Shrinkage (statistics) - Wikipedia"),n(t)])])]),Pa,e("blockquote",null,[e("p",null,[e("a",Ea,[a("Data transformation (statistics) - Wikipedia"),n(t)])])]),qa,e("ul",null,[e("li",null,[Ma,a(": Data conversion method. Currently, "),e("a",Oa,[a("FFT"),n(t)]),a(" and IFFT (Inverse Fast Fourier Transform) are supported.")])]),Ra,ja,Fa,e("blockquote",null,[e("p",null,[e("a",za,[a("Dimensionality reduction - Wikipedia"),n(t)])])]),Wa,e("ul",null,[e("li",null,[Ya,a(": Dimensionality reduction method. Currently supports "),e("a",Ba,[a("PCA"),n(t)]),a(" and "),e("a",Ua,[a("LDA"),n(t)]),a(" two methods.")]),Ga]),Ha,Ka,Va,e("blockquote",null,[e("p",null,[e("a",$a,[a("Oversampling and undersampling in data analysis - Wikipedia"),n(t)])])]),Ja,e("ul",null,[e("li",null,[Za,a(": Sample balancing method. Currently supports "),Qa,a(" ("),e("a",Xa,[a("RandomUnderSampler"),n(t)]),a("), "),et,a(" ("),e("a",at,[a("RandomOverSampler"),n(t)]),a(") and "),tt,a(" ï¼ˆ"),e("a",nt,[a("SMOTEENN"),n(t)]),a(") three methods.")])]),it,ot,st,e("blockquote",null,[e("p",null,[e("a",rt,[a("Normalization (statistics) - Wikipedia"),n(t)])])]),lt,e("ul",null,[e("li",null,[dt,a(": Normalization method. Currently supports "),e("a",ct,[a("Min_Max"),n(t)]),a(" and "),e("a",ht,[a("Z_Score"),n(t)]),a(" two methods.")])]),pt,e("ul",null,[ut,mt,gt,ft,bt,e("li",null,[a("Algorithm: Algorithm used to compute the nearest neighbors. Selection values: "),e("ul",null,[_t,e("li",null,[a("ball_tree: will use "),e("a",vt,[yt,n(t)])]),e("li",null,[a("kd_tree: will use ["),wt,a("]("),e("a",kt,[a("k-d tree - Wikipedia"),n(t)]),a(")")]),xt])]),Tt,At]),Ct,e("p",null,[a("LCDA reserves the right to review all content posted in the forum. If any content is found to be in violation of the "),e("a",Dt,[a("LCDA Terms & Conditions"),n(t)]),a(", LCDA reserves the right to delete the content without prior notice.")]),St])}const Rt=w(Q,[["render",It],["__file","all-in-one.html.vue"]]);export{Rt as default};
